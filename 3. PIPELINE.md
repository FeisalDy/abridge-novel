# Condensation Pipeline

This document defines the high-level condensation pipeline used by the Abridge project.

The pipeline describes **what happens at each stage**, what goes in, what comes out, and why each stage exists.

The pipeline is designed to be:
- Deterministic (given same input, same output)
- Hierarchical (chapter → arc → novel)
- Faithful to the original narrative
- Scalable to very long novels (via recursive reduction)

---

## 1. Pipeline Overview

The condensation process is performed in three required stages, each reducing length while preserving plot, causality, and readability.

High-level flow:

```
Raw Chapters
→ [Stage 1] Condensed Chapters
→ [Stage 2] Condensed Arcs
→ [Stage 3] Final Condensed Novel
```

Each stage uses the **same base condensation prompt** (`BASE_CONDENSATION_PROMPT` from `prompt.py`).
Only the input scope changes.

---

## 2. Stage 1: Chapter Condensation

**Implementation:** `chapter_condensation.py`

### Input
- Individual raw chapter files from `data/raw/{novel_name}/`
- Chapters are processed independently (no cross-chapter awareness)
- Files must have `.txt` extension

### Resume Behavior
- Strict 1:1 mapping: each raw chapter produces one condensed chapter
- Missing chapters are detected by comparing input vs output file counts
- Only missing chapters are processed; existing outputs are never overwritten
- Empty output files are treated as corrupted and reprocessed

### Process
1. Load raw chapter text
2. Apply prefilter (removes chapter headers, non-narrative content)
3. Inject text into `BASE_CONDENSATION_PROMPT`
4. Send to LLM with retry logic (up to 3 attempts)
5. Record guardrail event (length ratio monitoring)
6. Record LLM usage event (cost tracking)
7. Write condensed output

### Output
- One condensed chapter per original chapter
- Location: `data/chapters_condensed/{novel_name}/{filename}.condensed.txt`
- Output is readable as a standalone narrative unit

### Guardrail Thresholds (Chapter-Level)
- GREEN: ratio 0.40 – 0.70
- YELLOW: ratio 0.30 – 0.40 OR 0.70 – 0.85
- RED: ratio < 0.30 OR > 0.85

---

## 3. Stage 2: Arc Condensation

**Implementation:** `arc_condensation.py`

### Input
- All condensed chapter files from `data/chapters_condensed/{novel_name}/`
- Chapters are sorted alphabetically for deterministic grouping

### Arc Grouping Rules
- Fixed grouping: `CHAPTERS_PER_ARC = 10` chapters per arc (hardcoded)
- Last arc may have fewer than 10 chapters
- No semantic or thematic grouping is performed
- Arc indices are 1-based

### Resume Behavior
- Arc indices are computed from chapter count
- Missing arcs are detected by comparing expected vs existing output files
- Only missing arcs are processed; existing outputs are never overwritten
- Empty output files are treated as corrupted and reprocessed

### Process
1. Load all condensed chapter files (sorted)
2. Compute arc groupings based on `CHAPTERS_PER_ARC`
3. For each arc:
   - Concatenate chapter texts with separators
   - Apply `BASE_CONDENSATION_PROMPT` via LLM
   - Record guardrail event
   - Record LLM usage event
   - Write arc output

### Output
- One condensed arc per chapter group
- Location: `data/arcs_condensed/{novel_name}/arc_{XX}.condensed.txt`

### Guardrail Thresholds (Arc-Level)
- GREEN: ratio 0.25 – 0.50
- YELLOW: ratio 0.15 – 0.25 OR 0.50 – 0.65
- RED: ratio < 0.15 OR > 0.65

---

## 4. Stage 3: Novel Condensation

**Implementation:** `novel_condensation.py`

### Input
- All condensed arc files from `data/arcs_condensed/{novel_name}/`
- Arcs are sorted alphabetically for deterministic merging

### Scalability Algorithm
Novel condensation uses recursive reduction (`reduce_until_fit`) to handle arbitrarily large novels:

```
reduce_until_fit(text, max_tokens):
    if estimate_tokens(text) <= max_tokens:
        return llm_condense(text)
    
    # Split into halves, reduce each
    mid = len(text) // 2
    left = reduce_until_fit(text[:mid], max_tokens)
    right = reduce_until_fit(text[mid:], max_tokens)
    
    # Combine and reduce again
    return reduce_until_fit(left + right, max_tokens)
```

### Output Token Budget
- `SAFE_OUTPUT_TOKEN_BUDGET`: 55,000 tokens (default, configurable via env)
- `ESTIMATED_COMPRESSION_RATIO`: 0.45 (conservative estimate)
- Output-capped prompts add explicit length constraints to prevent truncation

### Output
- Single final condensation file
- Location: `data/novel_condensed/{novel_name}/novel.condensed.txt`
- Target length: approximately 10,000–50,000 words (depends on novel size)

---

## 5. Base Condensation Prompt

**Source:** `prompt.py`

The same prompt is used at all three stages:

**Role:** Disciplined literary editor

**Preservation Rules:**
- Preserve all events, actions, decisions, and outcomes
- Preserve chronology and causal relationships
- Do not reorder events or scenes
- Do not infer or add information not in source
- Do not omit events that influence future developments

**Removal Rules:**
- Remove repetition, padding, and filler that do not affect outcomes
- Do not rewrite into an abstract summary

**Style Requirements:**
- Neutral tone
- Third-person perspective
- Past tense
- Continuous narrative prose
- No meta commentary
- **Output must match input language** (no translation or normalization)

---

## 6. Persistence and File Handling

All intermediate outputs are preserved in separate directories:

| Stage | Location |
|-------|----------|
| Raw chapters | `data/raw/{novel_name}/` |
| Condensed chapters | `data/chapters_condensed/{novel_name}/` |
| Condensed arcs | `data/arcs_condensed/{novel_name}/` |
| Novel condensation | `data/novel_condensed/{novel_name}/` |

**Rules:**
- Intermediate files are NEVER silently overwritten
- Resume detection compares input vs output counts
- Empty files are treated as corrupted

---

## 7. Scope Boundaries

This pipeline is LIMITED to:
- Text condensation (input → shorter output)
- Length ratio monitoring (guardrails)
- Cost tracking (LLM usage)

This pipeline does **NOT** include:
- Genre detection (see Tier-3.4a)
- Tag detection (see Tier-3.4b)
- Character indexing (see Tier-2)
- Relationship graphs (see Tier-3.2)
- Scene detection
- Quality scoring
- UI or presentation layers

Those features exist as separate, optional pipeline stages that consume condensation outputs.

---

## 8. Editorial Identity

The pipeline enforces a single identity:

> Abridge behaves like a disciplined editor working in multiple passes,
> cutting excess while preserving the story.

All decisions are mechanical and deterministic.
No interpretation, judgment, or creative rewriting is performed.
