# NovelAbridge: Data Pipeline & Directory Structure

This document defines the architectural standards for the novel condensation pipeline. The core philosophy is **unidirectional data flow**: each stage reads from one source and writes to one destination.

---

## 1. Project Root Structure
```text
NovelAbridge/
├── run_pipeline.py           # Pipeline orchestrator (entry point)
├── prompt.py                 # Centralized LLM prompt templates
├── chapter_condensation.py   # Stage 1: Chapter condensation
├── arc_condensation.py       # Stage 2: Arc condensation
├── novel_condensation.py     # Stage 3: Novel condensation
├── guardrails.py             # Length ratio monitoring (observational)
├── cost_tracking.py          # LLM usage tracking (observational)
├── run_report.py             # Unified run report generation
├── character_indexing.py     # Tier-2: Character surface index
├── character_salience.py     # Tier-3.1: Character salience scores
├── relationship_matrix.py    # Tier-3.2: Co-presence signals
├── event_keywords.py         # Tier-3.3: Event keyword surface map
├── genre_resolver.py         # Tier-3.4a: Rule-based genre detection
├── tag_resolver.py           # Tier-3.4b: Rule-based tag detection
├── prefilter.py              # Chapter prefiltering (header removal)
├── utils.py                  # Shared utilities (reduce_until_fit, etc.)
├── llm/                      # LLM provider abstraction layer
│   ├── __init__.py
│   ├── llm_config.py
│   ├── llm_manager.py
│   └── {provider}_llm.py     # Provider-specific implementations
└── data/                     # The Data Lake (ignored by git)
```

## 2. Data Lake Overview
```text
data/
├── raw/                      # Input: Raw chapter files
├── chapters_condensed/       # Stage 1 output
├── arcs_condensed/           # Stage 2 output
├── novel_condensed/          # Stage 3 output
├── character_index/          # Tier-2 output
├── character_salience/       # Tier-3.1 output
├── relationship_matrix/      # Tier-3.2 output
├── event_keywords/           # Tier-3.3 output
├── genre_resolved/           # Tier-3.4a output
├── tag_resolved/             # Tier-3.4b output
└── reports/                  # Unified run reports (JSON + Markdown)
```

## 3. Raw Input Structure
```text
data/raw/
└── {novel_name}/
    ├── chapter_001.txt
    ├── chapter_002.txt
    ├── chapter_003.txt
    └── ...
```

**Requirements:**
- Files must have `.txt` extension
- Files are sorted alphabetically for deterministic processing
- Directory name becomes `{novel_name}` identifier

## 4. Condensed Chapters Output
```text
data/chapters_condensed/
└── {novel_name}/
    ├── chapter_001.condensed.txt
    ├── chapter_002.condensed.txt
    ├── chapter_003.condensed.txt
    └── ...
```

**1:1 Mapping:** Each raw chapter produces exactly one condensed chapter.

## 5. Condensed Arcs Output
```text
data/arcs_condensed/
└── {novel_name}/
    ├── arc_01.condensed.txt
    ├── arc_02.condensed.txt
    └── ...
```

**Grouping:** Each arc contains `CHAPTERS_PER_ARC=10` chapters (last arc may have fewer).

## 6. Final Condensed Novel Output
```text
data/novel_condensed/
└── {novel_name}/
    └── novel.condensed.txt
```

**Single file:** The final condensed narrative.

## 7. Tier-2/3 Feature Outputs

### Character Index (Tier-2)
```text
data/character_index/
└── {novel_name}/
    └── {run_id}.character_index.json
```

### Character Salience (Tier-3.1)
```text
data/character_salience/
└── {novel_name}/
    └── {run_id}.character_salience.json
```

### Relationship Matrix (Tier-3.2)
```text
data/relationship_matrix/
└── {novel_name}/
    └── {run_id}.relationship_matrix.json
```

### Event Keywords (Tier-3.3)
```text
data/event_keywords/
└── {novel_name}/
    └── {run_id}.event_keywords.json
```

### Genre Resolved (Tier-3.4a)
```text
data/genre_resolved/
└── {novel_name}/
    └── {run_id}.genre_resolved.json
```

### Tag Resolved (Tier-3.4b)
```text
data/tag_resolved/
└── {novel_name}/
    └── {run_id}.tag_resolved.json
```

**Note:** Tier-2/3 outputs are keyed by `run_id` to preserve history.

## 8. Run Reports
```text
data/reports/
├── run_20251231_044311_bf2e5ace.json
├── run_20251231_044311_bf2e5ace.md
└── ...
```

**Format:** `run_{YYYYMMDD}_{HHMMSS}_{uuid}.{json|md}`

## 9. SQLite Persistence

Guardrails and cost tracking persist to SQLite (outside data/ directory):

```text
NovelAbridge/
└── abridge_guardrails.db     # SQLite database
    ├── guardrail_events      # Length ratio events
    └── llm_usage_events      # Token usage events
```

**Tables:**
- `guardrail_events`: run_id, stage, unit_id, input_length, output_length, ratio, status, created_at
- `llm_usage_events`: run_id, stage, unit_id, model, input_tokens, output_tokens, estimated_cost, created_at